---
title: "Assignment 1"
author: "Callin Switzer"
date: "September 8, 2014"
output: html_document
---

```{r setup, results='hide', echo =FALSE}
# function to load required packages
ipak <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if(length(new.pkg)) install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

packages <- c("ggplot2", "data.table")
ipak(packages); rm(ipak); rm(packages)

```

normal

**bold**

*italic*

1. (Not Graded) Complete the following Conceptual Exercises in Chapter 1 (2nd or 3rd edition
of R&S): 2, 7, 9. Feel free to include your answers in the write-up. However, this question will
not be graded.
2. (20 points) For each of the following surveys, specify study units, the target population, and
the sampling frame. Discuss in 2-3 sentences any possible sources of selection bias, specifically,
undercoverage or overcoverage. Finally, specify what type of sampling was used.
     (a) (10 points) To estimate how many books in the library need rebinding, a librarian uses
     a random number generator to select 100 locations on library shelves. He then walks to
     each location, looks at the book that resides at that spot, and records whether the book
     needs rebinding or not.
          
          <font style="background-color: yellow;">
               * Study units = books in the library <br>
               * Target population = all the books in the library <br>
               * Sampling frame = all the books in the library <br>
               * Selection Bias: Undercoverage could occur if books were checked out or misplaced
               , and the librarian was unable to find them on the shelves.  Overcoverage could occur
               if the librarian found books that were not supposed to be in the libary -- for 
               example, someone could have returned a book to the library that didn't belong 
               to the library. <br>
               * Sampling = simple random sample
          
          </font>


     (b) (10 points) The Arizona Intrastate Travel Committee commissioned a study to identify
     in-state travel patterns of residents of major metropolitan cities and to evaluate different
     sources of vacation planning information. The plan was to conduct phone interviews with
     Phoenix and Tucson residents. Landline telephone numbers with Phoenix and Tucson
     area codes were generated randomly so that listed and unlisted telephone numbers could
     be reached. (Arizona Office of Tourism, 1991.)
          
          <font style="background-color: yellow;">
               * Study units = residents of major Phoenix and Tucson with phone numbers in those area codes <br>
               * Target population = all the road-users in the major metropolitan cities <br>
               * Sampling frame = all the people with a landline in Phoenix and Tucson <br>
               * Selection bias: Undercoverage could occur if people lived in Phoenix or Tucson 
               and didn't have a landline phone, or didn't answer their phone.  Overcoverage could
               occur if someone who wasn't a resident of a major metropolitan area answered the phone -- 
               for example, someone could have holiday home in a major city, and not live there for most 
               of the year. <br>
               * Sampling = simple random sample
          </font>

3. (5 points) Consider two securities, the first having expected return µ1 = 1 and standard
deviation σ1 = 0.1, and the second having µ2 = 0.8 and σ = 0.12. Also, let the correlation
between securities be ρ = 0.1. Suppose you invest π = 0.8, or 80%, of your money in the first
security and 1-π in the second security. What is your expected return and what is the standard
deviation of your return?

```{r, results = 'hide', echo = F}
mo <- 0.8*(1) + 0.2*(0.8)
va <- sqrt(0.8) * 0.1^2 + sqrt(0.2) * 0.12^2 + 2 * 0.8 * 0.2 * 0.1 * sqrt(0.1 + 0.12)
```

     <font style="background-color: yellow;">
          E(X)      = π(X1) + (1-π)(X2) <br>
                    = 0.8(1) + 0.2(0.8) <br> 
                    = `r I(mo)` is the expected return <br> </font>
     
     <font style="background-color: yellow;">         
     Var(X)    = sqrt(π) * Var(X1) + sqrt(1-π) * Var(X2) + 2 * π * (1-π) Cov(X1,X2) <br>
               = sqrt(0.8) * 0.1^2 + sqrt(0.2) * 0.12^2 + 2 * 0.8 * 0.2 * 0.1 * sqrt(0.1 + 0.12) <br>
               = `r va` is the standard deviation of the return<br>   
     </font>

4.  (10 points) Solve the following equations for the matrix X. You can assume that the matrices
A and B (when needed) are all invertible n x n matrices.
(a) AXB = C
(b) (AX) + B = D
(c) Solve equation (b) for X by hand if









5.  (15 points) The csdata.txt data set on the course web-site contains information on 224
computer science students. Use R to perform the following tasks:
     (a) Split the students into two groups with GPA < 3 and GPA ≥ 3 and provide the following
     numerical summaries of the distributions of SAT Math (SATM) scores for each of the two
     groups: sample mean, sample SD, min, median, max, 1st and 3rd quartiles.
```{r split and summarize, results='hold'}
# import data
stud <- read.table("data/CSDATA.txt", header = T)
stud$gpaGroup <- ifelse(stud$GPA > 3, yes = "High", no = "Low")

# split into low and high
high <- stud[stud$gpaGroup == "High", ]
low <- stud[ stud$gpaGroup == "Low",]

# custom summary function to include sd
mysum <- function(vector) {
     s <- numeric(7)
     names(s) <- c("sample mean", "sample SD", "min", "median", 
                   "max", "1st quartile","3rd quartile") 
     s[c(1,3,4,5,6,7)] <- summary(vector)[c(4, 1, 3, 6, 2, 5)]
     s[2] <- round(sd(vector), digits = 1)
     return(s)
}
```
<font style="background-color: yellow;"> 
Summary for high-gpa students
```{r, echo = F}
mysum(high$SATM)
```

<font style="background-color: yellow;"> Summary for low-gpa students
```{r, echo = F}
mysum(low$SATM)
```

(b) Plot histograms and box-plots of SATM scores for both groups side-by-side and describe
the shapes of their distributions. Are there any visible differences?

```{r hist, results = "hold", echo = F, fig.width= 6, fig.height=4}
stud$gpaGroup <- factor(stud$gpaGroup)

ggplot(stud) + 
     geom_histogram(aes(SATM, fill = gpaGroup), binwidth = 50, color = "grey40") +
     theme_bw() +
     facet_wrap(~gpaGroup) + 
     theme(legend.position = "none") +  
     ggtitle("SAT Math scores for high and low gpa students") + 
     labs(x = "SAT Math Scores")


ggplot(stud, aes(x = gpaGroup, y = SATM)) +
     geom_boxplot(aes(fill = gpaGroup), color = "grey40") + 
     theme_bw() +
     theme(legend.position = "none") + 
     ggtitle("Boxplot of SAT Math scores for low and high gpa students")+ 
     labs(x = "GPA Group", y ="SAT Maths Score")
```

<font style="background-color: yellow;"> Both distributions seem to be fairly normally distributed. They both have similar variances and neither seems especially skewed.
There are more poeple in the low-gpa group, as evidenced by the taller histogram.  The distribution
of SATM scores from the high-gpa group has a slightly higher mean than the low-gpa group. </font>

(c) Comment on whether you think the group means are very different or not (without con- ducting any formal tests).
<font style="background-color: yellow;"> The sample group means differ by about 40 points. This is quite a large difference -- I suspect that it's highly unlikely to find that large of a difference if the sample was random.  Thus, I think the group means are different. </font>

(d) Calculate the overall median SATM score in the sample and interpret it.
```{r median, echo = FALSE}
mm <- median(stud$SATM)
```
<font style="background-color: yellow;">
The overall median SATM score is `r mm`, which is basically right in the middle of two groups. Since the data are distributed fairly normally, the median is quite close to the mean.  The median is the score that 50% of the other scores fall below, and 50% fall above. </font>



(e) SAT is calibrated such that scores in the entire student population are distributed approx- imately normally with mean 500 and standard deviation 110. Identifying what fraction of student population is expected to score above the sample median found in the previous part? (Hint: use the R command pnorm() to find normal probabilities.) Are your findings consistent with an assertion that CS students have stronger math skills?